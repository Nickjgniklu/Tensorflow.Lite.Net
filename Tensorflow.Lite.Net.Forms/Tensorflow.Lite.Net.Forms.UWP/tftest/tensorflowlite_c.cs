// ----------------------------------------------------------------------------
// <auto-generated>
// This is autogenerated code by CppSharp.
// Do not edit this file or all your changes will be lost after re-generation.
// </auto-generated>
// ----------------------------------------------------------------------------
using System;
using System.Runtime.InteropServices;
using System.Security;
using __CallingConvention = global::System.Runtime.InteropServices.CallingConvention;
using __IntPtr = global::System.IntPtr;


namespace tensorflowlite_c
{
    public static class LibNames
    {
#if Android
        public const string TFLiteLib = "libtensorflowlite_c.so";
#elif UWP
        public const string TFLiteLib = "lib/x64/tensorflowlite_c.dll";
#else
        public const string TFLiteLib = "lib/x64/tensorflowlite_c.dll";
#endif

    }
    public unsafe partial class TfLiteModel
    {
        public partial struct __Internal
        {
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteModel> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteModel>();

        protected bool __ownsNativeInstance;

        internal static TfLiteModel __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteModel(native.ToPointer(), skipVTables);
        }

        internal static TfLiteModel __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteModel)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteModel __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteModel(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteModel(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteModel(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }
    }

    public unsafe partial class TfLiteInterpreterOptions
    {
        public partial struct __Internal
        {
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteInterpreterOptions> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteInterpreterOptions>();

        protected bool __ownsNativeInstance;

        internal static TfLiteInterpreterOptions __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteInterpreterOptions(native.ToPointer(), skipVTables);
        }

        internal static TfLiteInterpreterOptions __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteInterpreterOptions)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteInterpreterOptions __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteInterpreterOptions(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteInterpreterOptions(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteInterpreterOptions(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }
    }

    public unsafe partial class TfLiteInterpreter
    {
        public partial struct __Internal
        {
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteInterpreter> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteInterpreter>();

        protected bool __ownsNativeInstance;

        internal static TfLiteInterpreter __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteInterpreter(native.ToPointer(), skipVTables);
        }

        internal static TfLiteInterpreter __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteInterpreter)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteInterpreter __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteInterpreter(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteInterpreter(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteInterpreter(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }
    }

    public unsafe partial class c_api
    
    {

        public partial struct __Internal
        {
            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteVersion", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteVersion();

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteModelCreate", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteModelCreate(__IntPtr model_data, ulong model_size);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteModelCreateFromFile", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteModelCreateFromFile([MarshalAs(UnmanagedType.CustomMarshaler, MarshalTypeRef = typeof(CppSharp.Runtime.UTF8Marshaller))] string model_path);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteModelDelete", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteModelDelete(__IntPtr model);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterOptionsCreate", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteInterpreterOptionsCreate();

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterOptionsDelete", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteInterpreterOptionsDelete(__IntPtr options);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterOptionsSetNumThreads", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteInterpreterOptionsSetNumThreads(__IntPtr options, int num_threads);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterOptionsAddDelegate", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteInterpreterOptionsAddDelegate(__IntPtr options, __IntPtr @delegate);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterCreate", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteInterpreterCreate(__IntPtr model, __IntPtr optional_options);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterDelete", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteInterpreterDelete(__IntPtr interpreter);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterGetInputTensorCount", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteInterpreterGetInputTensorCount(__IntPtr interpreter);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterGetInputTensor", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteInterpreterGetInputTensor(__IntPtr interpreter, int input_index);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterResizeInputTensor", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern global::tensorflowlite_c.TfLiteStatus TfLiteInterpreterResizeInputTensor(__IntPtr interpreter, int input_index, int* input_dims, int input_dims_size);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterAllocateTensors", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern global::tensorflowlite_c.TfLiteStatus TfLiteInterpreterAllocateTensors(__IntPtr interpreter);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterInvoke", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern global::tensorflowlite_c.TfLiteStatus TfLiteInterpreterInvoke(__IntPtr interpreter);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterGetOutputTensorCount", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteInterpreterGetOutputTensorCount(__IntPtr interpreter);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteInterpreterGetOutputTensor", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteInterpreterGetOutputTensor(__IntPtr interpreter, int output_index);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorType", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern global::tensorflowlite_c.TfLiteType TfLiteTensorType(__IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorNumDims", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteTensorNumDims(__IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorDim", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteTensorDim(__IntPtr tensor, int dim_index);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorByteSize", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern ulong TfLiteTensorByteSize(__IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorData", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteTensorData(__IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorName", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteTensorName(__IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorQuantizationParams", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern global::tensorflowlite_c.TfLiteQuantizationParams.__Internal TfLiteTensorQuantizationParams(__IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorCopyFromBuffer", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern global::tensorflowlite_c.TfLiteStatus TfLiteTensorCopyFromBuffer(__IntPtr tensor, __IntPtr input_data, ulong input_data_size);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorCopyToBuffer", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern global::tensorflowlite_c.TfLiteStatus TfLiteTensorCopyToBuffer(__IntPtr output_tensor, __IntPtr output_data, ulong output_data_size);
        }

        public static string TfLiteVersion()
        {
            var __ret = __Internal.TfLiteVersion();
            return CppSharp.Runtime.MarshalUtil.GetString(global::System.Text.Encoding.UTF8, __ret);
        }

        public static global::tensorflowlite_c.TfLiteModel TfLiteModelCreate(__IntPtr model_data, ulong model_size)
        {
            var __ret = __Internal.TfLiteModelCreate(model_data, model_size);
            var __result0 = global::tensorflowlite_c.TfLiteModel.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static global::tensorflowlite_c.TfLiteModel TfLiteModelCreateFromFile(string model_path)
        {
            var __ret = __Internal.TfLiteModelCreateFromFile(model_path);
            var __result0 = global::tensorflowlite_c.TfLiteModel.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static void TfLiteModelDelete(global::tensorflowlite_c.TfLiteModel model)
        {
            var __arg0 = model is null ? __IntPtr.Zero : model.__Instance;
            __Internal.TfLiteModelDelete(__arg0);
        }

        public static global::tensorflowlite_c.TfLiteInterpreterOptions TfLiteInterpreterOptionsCreate()
        {
            var __ret = __Internal.TfLiteInterpreterOptionsCreate();
            var __result0 = global::tensorflowlite_c.TfLiteInterpreterOptions.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static void TfLiteInterpreterOptionsDelete(global::tensorflowlite_c.TfLiteInterpreterOptions options)
        {
            var __arg0 = options is null ? __IntPtr.Zero : options.__Instance;
            __Internal.TfLiteInterpreterOptionsDelete(__arg0);
        }

        public static void TfLiteInterpreterOptionsSetNumThreads(global::tensorflowlite_c.TfLiteInterpreterOptions options, int num_threads)
        {
            var __arg0 = options is null ? __IntPtr.Zero : options.__Instance;
            __Internal.TfLiteInterpreterOptionsSetNumThreads(__arg0, num_threads);
        }

        public static void TfLiteInterpreterOptionsAddDelegate(global::tensorflowlite_c.TfLiteInterpreterOptions options, global::tensorflowlite_c.TfLiteDelegate @delegate)
        {
            var __arg0 = options is null ? __IntPtr.Zero : options.__Instance;
            var __arg1 = @delegate is null ? __IntPtr.Zero : @delegate.__Instance;
            __Internal.TfLiteInterpreterOptionsAddDelegate(__arg0, __arg1);
        }

        public static global::tensorflowlite_c.TfLiteInterpreter TfLiteInterpreterCreate(global::tensorflowlite_c.TfLiteModel model, global::tensorflowlite_c.TfLiteInterpreterOptions optional_options)
        {
            var __arg0 = model is null ? __IntPtr.Zero : model.__Instance;
            var __arg1 = optional_options is null ? __IntPtr.Zero : optional_options.__Instance;
            var __ret = __Internal.TfLiteInterpreterCreate(__arg0, __arg1);
            var __result0 = global::tensorflowlite_c.TfLiteInterpreter.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static void TfLiteInterpreterDelete(global::tensorflowlite_c.TfLiteInterpreter interpreter)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            __Internal.TfLiteInterpreterDelete(__arg0);
        }

        public static int TfLiteInterpreterGetInputTensorCount(global::tensorflowlite_c.TfLiteInterpreter interpreter)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            var __ret = __Internal.TfLiteInterpreterGetInputTensorCount(__arg0);
            return __ret;
        }

        public static global::tensorflowlite_c.TfLiteTensor TfLiteInterpreterGetInputTensor(global::tensorflowlite_c.TfLiteInterpreter interpreter, int input_index)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            var __ret = __Internal.TfLiteInterpreterGetInputTensor(__arg0, input_index);
            var __result0 = global::tensorflowlite_c.TfLiteTensor.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static global::tensorflowlite_c.TfLiteStatus TfLiteInterpreterResizeInputTensor(global::tensorflowlite_c.TfLiteInterpreter interpreter, int input_index, ref int input_dims, int input_dims_size)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            fixed (int* __input_dims2 = &input_dims)
            {
                var __arg2 = __input_dims2;
                var __ret = __Internal.TfLiteInterpreterResizeInputTensor(__arg0, input_index, __arg2, input_dims_size);
                return __ret;
            }
        }

        public static global::tensorflowlite_c.TfLiteStatus TfLiteInterpreterAllocateTensors(global::tensorflowlite_c.TfLiteInterpreter interpreter)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            var __ret = __Internal.TfLiteInterpreterAllocateTensors(__arg0);
            return __ret;
        }

        public static global::tensorflowlite_c.TfLiteStatus TfLiteInterpreterInvoke(global::tensorflowlite_c.TfLiteInterpreter interpreter)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            var __ret = __Internal.TfLiteInterpreterInvoke(__arg0);
            return __ret;
        }

        public static int TfLiteInterpreterGetOutputTensorCount(global::tensorflowlite_c.TfLiteInterpreter interpreter)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            var __ret = __Internal.TfLiteInterpreterGetOutputTensorCount(__arg0);
            return __ret;
        }

        public static global::tensorflowlite_c.TfLiteTensor TfLiteInterpreterGetOutputTensor(global::tensorflowlite_c.TfLiteInterpreter interpreter, int output_index)
        {
            var __arg0 = interpreter is null ? __IntPtr.Zero : interpreter.__Instance;
            var __ret = __Internal.TfLiteInterpreterGetOutputTensor(__arg0, output_index);
            var __result0 = global::tensorflowlite_c.TfLiteTensor.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static global::tensorflowlite_c.TfLiteType TfLiteTensorType(global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorType(__arg0);
            return __ret;
        }

        public static int TfLiteTensorNumDims(global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorNumDims(__arg0);
            return __ret;
        }

        public static int TfLiteTensorDim(global::tensorflowlite_c.TfLiteTensor tensor, int dim_index)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorDim(__arg0, dim_index);
            return __ret;
        }

        public static ulong TfLiteTensorByteSize(global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorByteSize(__arg0);
            return __ret;
        }

        public static __IntPtr TfLiteTensorData(global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorData(__arg0);
            return __ret;
        }

        public static string TfLiteTensorName(global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorName(__arg0);
            return CppSharp.Runtime.MarshalUtil.GetString(global::System.Text.Encoding.UTF8, __ret);
        }

        public static global::tensorflowlite_c.TfLiteQuantizationParams TfLiteTensorQuantizationParams(global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorQuantizationParams(__arg0);
            return global::tensorflowlite_c.TfLiteQuantizationParams.__CreateInstance(__ret);
        }

        public static global::tensorflowlite_c.TfLiteStatus TfLiteTensorCopyFromBuffer(global::tensorflowlite_c.TfLiteTensor tensor, __IntPtr input_data, ulong input_data_size)
        {
            var __arg0 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            var __ret = __Internal.TfLiteTensorCopyFromBuffer(__arg0, input_data, input_data_size);
            return __ret;
        }

        public static global::tensorflowlite_c.TfLiteStatus TfLiteTensorCopyToBuffer(global::tensorflowlite_c.TfLiteTensor output_tensor, __IntPtr output_data, ulong output_data_size)
        {
            var __arg0 = output_tensor is null ? __IntPtr.Zero : output_tensor.__Instance;
            var __ret = __Internal.TfLiteTensorCopyToBuffer(__arg0, output_data, output_data_size);
            return __ret;
        }
    }

    public enum TfLiteStatus
    {
        kTfLiteOk = 0,
        kTfLiteError = 1,
        kTfLiteDelegateError = 2,
        kTfLiteApplicationError = 3
    }

    public enum TfLiteExternalContextType
    {
        kTfLiteEigenContext = 0,
        kTfLiteGemmLowpContext = 1,
        kTfLiteEdgeTpuContext = 2,
        kTfLiteCpuBackendContext = 3,
        kTfLiteMaxExternalContexts = 4
    }

    public enum TfLiteType
    {
        kTfLiteNoType = 0,
        kTfLiteFloat32 = 1,
        kTfLiteInt32 = 2,
        kTfLiteUInt8 = 3,
        kTfLiteInt64 = 4,
        kTfLiteString = 5,
        kTfLiteBool = 6,
        kTfLiteInt16 = 7,
        kTfLiteComplex64 = 8,
        kTfLiteInt8 = 9,
        kTfLiteFloat16 = 10,
        kTfLiteFloat64 = 11,
        kTfLiteComplex128 = 12
    }

    public enum TfLiteAllocationType
    {
        kTfLiteMemNone = 0,
        kTfLiteMmapRo = 1,
        kTfLiteArenaRw = 2,
        kTfLiteArenaRwPersistent = 3,
        kTfLiteDynamic = 4,
        kTfLitePersistentRo = 5,
        kTfLiteCustom = 6
    }

    public enum TfLiteQuantizationType
    {
        kTfLiteNoQuantization = 0,
        kTfLiteAffineQuantization = 1
    }

    public enum TfLiteDimensionType
    {
        kTfLiteDimDense = 0,
        kTfLiteDimSparseCSR = 1
    }

    public enum KTfLiteNullBufferHandle
    {
        kTfLiteNullBufferHandle = -1
    }

    public enum TfLiteDelegateFlags
    {
        kTfLiteDelegateFlagsNone = 0,
        kTfLiteDelegateFlagsAllowDynamicTensors = 1,
        kTfLiteDelegateFlagsRequirePropagatedShapes = 2
    }

    public unsafe partial class TfLiteExternalContext : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 16)]
        public partial struct __Internal
        {
            internal global::tensorflowlite_c.TfLiteExternalContextType type;
            internal __IntPtr Refresh;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteExternalContext@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteExternalContext> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteExternalContext>();

        protected bool __ownsNativeInstance;

        internal static TfLiteExternalContext __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteExternalContext(native.ToPointer(), skipVTables);
        }

        internal static TfLiteExternalContext __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteExternalContext)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteExternalContext __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteExternalContext(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteExternalContext(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteExternalContext(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteExternalContext()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteExternalContext.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteExternalContext(global::tensorflowlite_c.TfLiteExternalContext _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteExternalContext.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteExternalContext.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteExternalContext.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteExternalContextType Type
        {
            get
            {
                return ((__Internal*)__Instance)->type;
            }

            set
            {
                ((__Internal*)__Instance)->type = value;
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr Refresh
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->Refresh;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->Refresh = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }
    }

    public unsafe partial class TfLiteIntArray : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 4)]
        public partial struct __Internal
        {
            internal int size;
            internal int* data;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteIntArray@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteIntArray> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteIntArray>();

        protected bool __ownsNativeInstance;

        internal static TfLiteIntArray __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteIntArray(native.ToPointer(), skipVTables);
        }

        internal static TfLiteIntArray __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteIntArray)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteIntArray __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteIntArray(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteIntArray(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteIntArray(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteIntArray()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteIntArray.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteIntArray(global::tensorflowlite_c.TfLiteIntArray _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteIntArray.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteIntArray.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteIntArray.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public int Size
        {
            get
            {
                return ((__Internal*)__Instance)->size;
            }

            set
            {
                ((__Internal*)__Instance)->size = value;
            }
        }

        public int* Data
        {
            get
            {
                return ((__Internal*)__Instance)->data;
            }

            set
            {
                ((__Internal*)__Instance)->data = value;
            }
        }
    }

    public unsafe partial class TfLiteFloatArray : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 4)]
        //public partial struct __Internal
        //{
        //    internal float re;
        //    internal float im;

        //    [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteComplex64@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
        //    internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        //}
        public partial struct __Internal
        {
            internal int size;
            internal float* data;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteFloatArray@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteFloatArray> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteFloatArray>();

        protected bool __ownsNativeInstance;

        internal static TfLiteFloatArray __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteFloatArray(native.ToPointer(), skipVTables);
        }

        internal static TfLiteFloatArray __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteFloatArray)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteFloatArray __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteFloatArray(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteFloatArray(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteFloatArray(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteFloatArray()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteFloatArray.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteFloatArray(global::tensorflowlite_c.TfLiteFloatArray _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteFloatArray.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteFloatArray.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteFloatArray.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public int Size
        {
            get
            {
                return ((__Internal*)__Instance)->size;
            }

            set
            {
                ((__Internal*)__Instance)->size = value;
            }
        }

        public float* Data
        {
            get
            {
                return ((__Internal*)__Instance)->data;
            }

            set
            {
                ((__Internal*)__Instance)->data = value;
            }
        }
    }

    public unsafe partial class TfLiteComplex64 : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 8)]
        public partial struct __Internal
        {
            internal float re;
            internal float im;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteComplex64@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteComplex64> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteComplex64>();

        protected bool __ownsNativeInstance;

        internal static TfLiteComplex64 __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteComplex64(native.ToPointer(), skipVTables);
        }

        internal static TfLiteComplex64 __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteComplex64)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteComplex64 __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteComplex64(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteComplex64(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteComplex64(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteComplex64()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteComplex64.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteComplex64(global::tensorflowlite_c.TfLiteComplex64 _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteComplex64.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteComplex64.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteComplex64.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public float Re
        {
            get
            {
                return ((__Internal*)__Instance)->re;
            }

            set
            {
                ((__Internal*)__Instance)->re = value;
            }
        }

        public float Im
        {
            get
            {
                return ((__Internal*)__Instance)->im;
            }

            set
            {
                ((__Internal*)__Instance)->im = value;
            }
        }
    }

    public unsafe partial class TfLiteComplex128 : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 16)]
        public partial struct __Internal
        {
            internal double re;
            internal double im;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteComplex128@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteComplex128> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteComplex128>();

        protected bool __ownsNativeInstance;

        internal static TfLiteComplex128 __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteComplex128(native.ToPointer(), skipVTables);
        }

        internal static TfLiteComplex128 __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteComplex128)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteComplex128 __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteComplex128(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteComplex128(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteComplex128(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteComplex128()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteComplex128.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteComplex128(global::tensorflowlite_c.TfLiteComplex128 _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteComplex128.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteComplex128.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteComplex128.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public double Re
        {
            get
            {
                return ((__Internal*)__Instance)->re;
            }

            set
            {
                ((__Internal*)__Instance)->re = value;
            }
        }

        public double Im
        {
            get
            {
                return ((__Internal*)__Instance)->im;
            }

            set
            {
                ((__Internal*)__Instance)->im = value;
            }
        }
    }

    public unsafe partial class TfLiteFloat16 : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 2)]
        public partial struct __Internal
        {
            internal ushort data;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteFloat16@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteFloat16> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteFloat16>();

        protected bool __ownsNativeInstance;

        internal static TfLiteFloat16 __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteFloat16(native.ToPointer(), skipVTables);
        }

        internal static TfLiteFloat16 __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteFloat16)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteFloat16 __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteFloat16(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteFloat16(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteFloat16(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteFloat16()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteFloat16.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteFloat16(global::tensorflowlite_c.TfLiteFloat16 _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteFloat16.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteFloat16.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteFloat16.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public ushort Data
        {
            get
            {
                return ((__Internal*)__Instance)->data;
            }

            set
            {
                ((__Internal*)__Instance)->data = value;
            }
        }
    }

    public unsafe partial class TfLiteQuantization : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 16)]
        public partial struct __Internal
        {
            internal global::tensorflowlite_c.TfLiteQuantizationType type;
            internal __IntPtr @params;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteQuantization@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteQuantization> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteQuantization>();

        protected bool __ownsNativeInstance;

        internal static TfLiteQuantization __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteQuantization(native.ToPointer(), skipVTables);
        }

        internal static TfLiteQuantization __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteQuantization)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteQuantization __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteQuantization(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteQuantization(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteQuantization(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteQuantization()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteQuantization.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteQuantization(global::tensorflowlite_c.TfLiteQuantization _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteQuantization.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteQuantization.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteQuantization.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteQuantizationType Type
        {
            get
            {
                return ((__Internal*)__Instance)->type;
            }

            set
            {
                ((__Internal*)__Instance)->type = value;
            }
        }

        public __IntPtr Params
        {
            get
            {
                return ((__Internal*)__Instance)->@params;
            }

            set
            {
                ((__Internal*)__Instance)->@params = (__IntPtr) value;
            }
        }
    }

    public unsafe partial class TfLiteQuantizationParams : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 8)]
        public partial struct __Internal
        {
            internal float scale;
            internal int zero_point;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteQuantizationParams@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteQuantizationParams> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteQuantizationParams>();

        protected bool __ownsNativeInstance;

        internal static TfLiteQuantizationParams __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteQuantizationParams(native.ToPointer(), skipVTables);
        }

        internal static TfLiteQuantizationParams __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteQuantizationParams)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteQuantizationParams __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteQuantizationParams(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteQuantizationParams(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteQuantizationParams(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteQuantizationParams()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteQuantizationParams.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteQuantizationParams(global::tensorflowlite_c.TfLiteQuantizationParams _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteQuantizationParams.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteQuantizationParams.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteQuantizationParams.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public float Scale
        {
            get
            {
                return ((__Internal*)__Instance)->scale;
            }

            set
            {
                ((__Internal*)__Instance)->scale = value;
            }
        }

        public int ZeroPoint
        {
            get
            {
                return ((__Internal*)__Instance)->zero_point;
            }

            set
            {
                ((__Internal*)__Instance)->zero_point = value;
            }
        }
    }

    public unsafe partial class TfLiteAffineQuantization : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 24)]
        public partial struct __Internal
        {
            internal __IntPtr scale;
            internal __IntPtr zero_point;
            internal int quantized_dimension;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteAffineQuantization@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteAffineQuantization> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteAffineQuantization>();

        protected bool __ownsNativeInstance;

        internal static TfLiteAffineQuantization __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteAffineQuantization(native.ToPointer(), skipVTables);
        }

        internal static TfLiteAffineQuantization __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteAffineQuantization)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteAffineQuantization __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteAffineQuantization(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteAffineQuantization(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteAffineQuantization(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteAffineQuantization()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteAffineQuantization.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteAffineQuantization(global::tensorflowlite_c.TfLiteAffineQuantization _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteAffineQuantization.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteAffineQuantization.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteAffineQuantization.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteFloatArray Scale
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteFloatArray.__GetOrCreateInstance(((__Internal*)__Instance)->scale, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->scale = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray ZeroPoint
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->zero_point, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->zero_point = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public int QuantizedDimension
        {
            get
            {
                return ((__Internal*)__Instance)->quantized_dimension;
            }

            set
            {
                ((__Internal*)__Instance)->quantized_dimension = value;
            }
        }
    }

    public unsafe partial struct TfLitePtrUnion
    {
        [StructLayout(LayoutKind.Explicit, Size = 8)]
        public partial struct __Internal
        {
            [FieldOffset(0)]
            internal __IntPtr i32;

            [FieldOffset(0)]
            internal __IntPtr i64;

            [FieldOffset(0)]
            internal __IntPtr f;

            [FieldOffset(0)]
            internal __IntPtr f16;

            [FieldOffset(0)]
            internal __IntPtr f64;

            [FieldOffset(0)]
            internal __IntPtr raw;

            [FieldOffset(0)]
            internal __IntPtr raw_const;

            [FieldOffset(0)]
            internal __IntPtr uint8;

            [FieldOffset(0)]
            internal __IntPtr b;

            [FieldOffset(0)]
            internal __IntPtr i16;

            [FieldOffset(0)]
            internal __IntPtr c64;

            [FieldOffset(0)]
            internal __IntPtr c128;

            [FieldOffset(0)]
            internal __IntPtr int8;

            [FieldOffset(0)]
            internal __IntPtr data;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLitePtrUnion@@QEAA@AEBT0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        private TfLitePtrUnion.__Internal __instance;
        internal TfLitePtrUnion.__Internal __Instance { get { return __instance; } }

        internal static TfLitePtrUnion __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLitePtrUnion(native.ToPointer(), skipVTables);
        }

        internal static TfLitePtrUnion __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLitePtrUnion(native, skipVTables);
        }

        private TfLitePtrUnion(__Internal native, bool skipVTables = false)
            : this()
        {
            __instance = native;
        }

        private TfLitePtrUnion(void* native, bool skipVTables = false) : this()
        {
            __instance = *(global::tensorflowlite_c.TfLitePtrUnion.__Internal*) native;
        }

        public TfLitePtrUnion(global::tensorflowlite_c.TfLitePtrUnion _0)
            : this()
        {
            var ____arg0 = _0.__Instance;
            var __arg0 = new __IntPtr(&____arg0);
            fixed (__Internal* __instancePtr = &__instance)
            {
                __Internal.cctor(new __IntPtr(__instancePtr), __arg0);
            }
        }

        public int* I32
        {
            get
            {
                return (int*) __instance.i32;
            }

            set
            {
                __instance.i32 = (__IntPtr) value;
            }
        }

        public long* I64
        {
            get
            {
                return (long*) __instance.i64;
            }

            set
            {
                __instance.i64 = (__IntPtr) value;
            }
        }

        public float* F
        {
            get
            {
                return (float*) __instance.f;
            }

            set
            {
                __instance.f = (__IntPtr) value;
            }
        }

        public global::tensorflowlite_c.TfLiteFloat16 F16
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteFloat16.__GetOrCreateInstance(__instance.f16, false);
                return __result0;
            }

            set
            {
                __instance.f16 = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public double* F64
        {
            get
            {
                return (double*) __instance.f64;
            }

            set
            {
                __instance.f64 = (__IntPtr) value;
            }
        }

        public sbyte* Raw
        {
            get
            {
                return (sbyte*) __instance.raw;
            }

            set
            {
                __instance.raw = (__IntPtr) value;
            }
        }

        public string RawConst
        {
            get
            {
                return CppSharp.Runtime.MarshalUtil.GetString(global::System.Text.Encoding.UTF8, __instance.raw_const);
            }

            set
            {
               // if (___instance.raw_const_OwnsNativeMemory)
              //      Marshal.FreeHGlobal(__instance.raw_const);
              //  ___instance.raw_const_OwnsNativeMemory = true;
                if (value == null)
                {
                    __instance.raw_const = global::System.IntPtr.Zero;
                    return;
                }
                var __bytes0 = global::System.Text.Encoding.UTF8.GetBytes(value);
                var __bytePtr0 = Marshal.AllocHGlobal(__bytes0.Length + 1);
                Marshal.Copy(__bytes0, 0, __bytePtr0, __bytes0.Length);
                Marshal.WriteByte(__bytePtr0 + __bytes0.Length, 0);
                __instance.raw_const = (__IntPtr) __bytePtr0;
            }
        }

        public byte* Uint8
        {
            get
            {
                return (byte*) __instance.uint8;
            }

            set
            {
                __instance.uint8 = (__IntPtr) value;
            }
        }

        public bool* B
        {
            get
            {
                return (bool*) __instance.b;
            }

            set
            {
                __instance.b = (__IntPtr) (byte) (value[0] ? 1 : 0);
            }
        }

        public short* I16
        {
            get
            {
                return (short*) __instance.i16;
            }

            set
            {
                __instance.i16 = (__IntPtr) value;
            }
        }

        public global::tensorflowlite_c.TfLiteComplex64 C64
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteComplex64.__GetOrCreateInstance(__instance.c64, false);
                return __result0;
            }

            set
            {
                __instance.c64 = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteComplex128 C128
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteComplex128.__GetOrCreateInstance(__instance.c128, false);
                return __result0;
            }

            set
            {
                __instance.c128 = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public sbyte* Int8
        {
            get
            {
                return (sbyte*) __instance.int8;
            }

            set
            {
                __instance.int8 = (__IntPtr) value;
            }
        }

        public __IntPtr Data
        {
            get
            {
                return __instance.data;
            }

            set
            {
                __instance.data = (__IntPtr) value;
            }
        }
    }

    public unsafe partial class TfLiteDimensionMetadata : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 24)]
        public partial struct __Internal
        {
            internal global::tensorflowlite_c.TfLiteDimensionType format;
            internal int dense_size;
            internal __IntPtr array_segments;
            internal __IntPtr array_indices;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteDimensionMetadata@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteDimensionMetadata> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteDimensionMetadata>();

        protected bool __ownsNativeInstance;

        internal static TfLiteDimensionMetadata __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteDimensionMetadata(native.ToPointer(), skipVTables);
        }

        internal static TfLiteDimensionMetadata __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteDimensionMetadata)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteDimensionMetadata __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteDimensionMetadata(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteDimensionMetadata(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteDimensionMetadata(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteDimensionMetadata()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteDimensionMetadata.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteDimensionMetadata(global::tensorflowlite_c.TfLiteDimensionMetadata _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteDimensionMetadata.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteDimensionMetadata.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteDimensionMetadata.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteDimensionType Format
        {
            get
            {
                return ((__Internal*)__Instance)->format;
            }

            set
            {
                ((__Internal*)__Instance)->format = value;
            }
        }

        public int DenseSize
        {
            get
            {
                return ((__Internal*)__Instance)->dense_size;
            }

            set
            {
                ((__Internal*)__Instance)->dense_size = value;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray ArraySegments
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->array_segments, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->array_segments = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray ArrayIndices
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->array_indices, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->array_indices = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }
    }

    public unsafe partial class TfLiteSparsity : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 32)]
        public partial struct __Internal
        {
            internal __IntPtr traversal_order;
            internal __IntPtr block_map;
            internal __IntPtr dim_metadata;
            internal int dim_metadata_size;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteSparsity@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteSparsity> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteSparsity>();

        protected bool __ownsNativeInstance;

        internal static TfLiteSparsity __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteSparsity(native.ToPointer(), skipVTables);
        }

        internal static TfLiteSparsity __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteSparsity)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteSparsity __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteSparsity(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteSparsity(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteSparsity(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteSparsity()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteSparsity.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteSparsity(global::tensorflowlite_c.TfLiteSparsity _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteSparsity.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteSparsity.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteSparsity.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteIntArray TraversalOrder
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->traversal_order, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->traversal_order = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray BlockMap
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->block_map, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->block_map = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteDimensionMetadata DimMetadata
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteDimensionMetadata.__GetOrCreateInstance(((__Internal*)__Instance)->dim_metadata, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->dim_metadata = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public int DimMetadataSize
        {
            get
            {
                return ((__Internal*)__Instance)->dim_metadata_size;
            }

            set
            {
                ((__Internal*)__Instance)->dim_metadata_size = value;
            }
        }
    }

    public unsafe partial class TfLiteCustomAllocation : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 16)]
        public partial struct __Internal
        {
            internal __IntPtr data;
            internal ulong bytes;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteCustomAllocation@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteCustomAllocation> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteCustomAllocation>();

        protected bool __ownsNativeInstance;

        internal static TfLiteCustomAllocation __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteCustomAllocation(native.ToPointer(), skipVTables);
        }

        internal static TfLiteCustomAllocation __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteCustomAllocation)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteCustomAllocation __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteCustomAllocation(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteCustomAllocation(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteCustomAllocation(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteCustomAllocation()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteCustomAllocation.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteCustomAllocation(global::tensorflowlite_c.TfLiteCustomAllocation _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteCustomAllocation.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteCustomAllocation.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteCustomAllocation.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public __IntPtr Data
        {
            get
            {
                return ((__Internal*)__Instance)->data;
            }

            set
            {
                ((__Internal*)__Instance)->data = (__IntPtr) value;
            }
        }

        public ulong Bytes
        {
            get
            {
                return ((__Internal*)__Instance)->bytes;
            }

            set
            {
                ((__Internal*)__Instance)->bytes = value;
            }
        }
    }

    public unsafe partial class TfLiteTensor : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 112)]
        public partial struct __Internal
        {
            internal global::tensorflowlite_c.TfLiteType type;
            internal global::tensorflowlite_c.TfLitePtrUnion.__Internal data;
            internal __IntPtr dims;
            internal global::tensorflowlite_c.TfLiteQuantizationParams.__Internal @params;
            internal global::tensorflowlite_c.TfLiteAllocationType allocation_type;
            internal ulong bytes;
            internal __IntPtr allocation;
            internal __IntPtr name;
            internal __IntPtr @delegate;
            internal int buffer_handle;
            internal byte data_is_stale;
            internal byte is_variable;
            internal global::tensorflowlite_c.TfLiteQuantization.__Internal quantization;
            internal __IntPtr sparsity;
            internal __IntPtr dims_signature;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteTensor@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteTensor> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteTensor>();
        private bool __name_OwnsNativeMemory = false;

        protected bool __ownsNativeInstance;

        internal static TfLiteTensor __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteTensor(native.ToPointer(), skipVTables);
        }

        internal static TfLiteTensor __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteTensor)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteTensor __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteTensor(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteTensor(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteTensor(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteTensor()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteTensor.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteTensor(global::tensorflowlite_c.TfLiteTensor _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteTensor.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteTensor.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteTensor.__Internal*) _0.__Instance);
            if (_0.__name_OwnsNativeMemory)
                this.Name = _0.Name;
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__name_OwnsNativeMemory)
                Marshal.FreeHGlobal(((__Internal*)__Instance)->name);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteType Type
        {
            get
            {
                return ((__Internal*)__Instance)->type;
            }

            set
            {
                ((__Internal*)__Instance)->type = value;
            }
        }

        public global::tensorflowlite_c.TfLitePtrUnion Data
        {
            get
            {
                return global::tensorflowlite_c.TfLitePtrUnion.__CreateInstance(((__Internal*)__Instance)->data);
            }

            set
            {
                ((__Internal*)__Instance)->data = value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray Dims
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->dims, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->dims = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteQuantizationParams Params
        {
            get
            {
                return global::tensorflowlite_c.TfLiteQuantizationParams.__CreateInstance(new __IntPtr(&((__Internal*)__Instance)->@params));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((__Internal*)__Instance)->@params = *(global::tensorflowlite_c.TfLiteQuantizationParams.__Internal*) value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteAllocationType AllocationType
        {
            get
            {
                return ((__Internal*)__Instance)->allocation_type;
            }

            set
            {
                ((__Internal*)__Instance)->allocation_type = value;
            }
        }

        public ulong Bytes
        {
            get
            {
                return ((__Internal*)__Instance)->bytes;
            }

            set
            {
                ((__Internal*)__Instance)->bytes = value;
            }
        }

        public __IntPtr Allocation
        {
            get
            {
                return ((__Internal*)__Instance)->allocation;
            }
        }

        public string Name
        {
            get
            {
                return CppSharp.Runtime.MarshalUtil.GetString(global::System.Text.Encoding.UTF8, ((__Internal*)__Instance)->name);
            }

            set
            {
                if (__name_OwnsNativeMemory)
                    Marshal.FreeHGlobal(((__Internal*)__Instance)->name);
                __name_OwnsNativeMemory = true;
                if (value == null)
                {
                    ((__Internal*)__Instance)->name = global::System.IntPtr.Zero;
                    return;
                }
                var __bytes0 = global::System.Text.Encoding.UTF8.GetBytes(value);
                var __bytePtr0 = Marshal.AllocHGlobal(__bytes0.Length + 1);
                Marshal.Copy(__bytes0, 0, __bytePtr0, __bytes0.Length);
                Marshal.WriteByte(__bytePtr0 + __bytes0.Length, 0);
                ((__Internal*)__Instance)->name = (__IntPtr) __bytePtr0;
            }
        }

        public global::tensorflowlite_c.TfLiteDelegate Delegate
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteDelegate.__GetOrCreateInstance(((__Internal*)__Instance)->@delegate, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->@delegate = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public int BufferHandle
        {
            get
            {
                return ((__Internal*)__Instance)->buffer_handle;
            }

            set
            {
                ((__Internal*)__Instance)->buffer_handle = value;
            }
        }

        public bool DataIsStale
        {
            get
            {
                return ((__Internal*)__Instance)->data_is_stale != 0;
            }

            set
            {
                ((__Internal*)__Instance)->data_is_stale = (byte) (value ? 1 : 0);
            }
        }

        public bool IsVariable
        {
            get
            {
                return ((__Internal*)__Instance)->is_variable != 0;
            }

            set
            {
                ((__Internal*)__Instance)->is_variable = (byte) (value ? 1 : 0);
            }
        }

        public global::tensorflowlite_c.TfLiteQuantization Quantization
        {
            get
            {
                return global::tensorflowlite_c.TfLiteQuantization.__CreateInstance(new __IntPtr(&((__Internal*)__Instance)->quantization));
            }

            set
            {
                if (ReferenceEquals(value, null))
                    throw new global::System.ArgumentNullException("value", "Cannot be null because it is passed by value.");
                ((__Internal*)__Instance)->quantization = *(global::tensorflowlite_c.TfLiteQuantization.__Internal*) value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteSparsity Sparsity
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteSparsity.__GetOrCreateInstance(((__Internal*)__Instance)->sparsity, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->sparsity = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray DimsSignature
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->dims_signature, false);
                return __result0;
            }
        }
    }

    public unsafe partial class TfLiteNode : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 72)]
        public partial struct __Internal
        {
            internal __IntPtr inputs;
            internal __IntPtr outputs;
            internal __IntPtr intermediates;
            internal __IntPtr temporaries;
            internal __IntPtr user_data;
            internal __IntPtr builtin_data;
            internal __IntPtr custom_initial_data;
            internal int custom_initial_data_size;
            internal __IntPtr @delegate;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteNode@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteNode> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteNode>();

        protected bool __ownsNativeInstance;

        internal static TfLiteNode __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteNode(native.ToPointer(), skipVTables);
        }

        internal static TfLiteNode __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteNode)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteNode __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteNode(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteNode(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteNode(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteNode()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteNode.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteNode(global::tensorflowlite_c.TfLiteNode _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteNode.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteNode.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteNode.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteIntArray Inputs
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->inputs, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->inputs = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray Outputs
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->outputs, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->outputs = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray Intermediates
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->intermediates, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->intermediates = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray Temporaries
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->temporaries, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->temporaries = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public __IntPtr UserData
        {
            get
            {
                return ((__Internal*)__Instance)->user_data;
            }

            set
            {
                ((__Internal*)__Instance)->user_data = (__IntPtr) value;
            }
        }

        public __IntPtr BuiltinData
        {
            get
            {
                return ((__Internal*)__Instance)->builtin_data;
            }

            set
            {
                ((__Internal*)__Instance)->builtin_data = (__IntPtr) value;
            }
        }

        public __IntPtr CustomInitialData
        {
            get
            {
                return ((__Internal*)__Instance)->custom_initial_data;
            }
        }

        public int CustomInitialDataSize
        {
            get
            {
                return ((__Internal*)__Instance)->custom_initial_data_size;
            }

            set
            {
                ((__Internal*)__Instance)->custom_initial_data_size = value;
            }
        }

        public global::tensorflowlite_c.TfLiteDelegate Delegate
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteDelegate.__GetOrCreateInstance(((__Internal*)__Instance)->@delegate, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->@delegate = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }
    }

    public unsafe partial class TfLiteEvalTensor : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 24)]
        public partial struct __Internal
        {
            internal global::tensorflowlite_c.TfLitePtrUnion.__Internal data;
            internal __IntPtr dims;
            internal global::tensorflowlite_c.TfLiteType type;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteEvalTensor@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteEvalTensor> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteEvalTensor>();

        protected bool __ownsNativeInstance;

        internal static TfLiteEvalTensor __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteEvalTensor(native.ToPointer(), skipVTables);
        }

        internal static TfLiteEvalTensor __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteEvalTensor)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteEvalTensor __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteEvalTensor(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteEvalTensor(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteEvalTensor(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteEvalTensor()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteEvalTensor.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteEvalTensor(global::tensorflowlite_c.TfLiteEvalTensor _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteEvalTensor.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteEvalTensor.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteEvalTensor.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLitePtrUnion Data
        {
            get
            {
                return global::tensorflowlite_c.TfLitePtrUnion.__CreateInstance(((__Internal*)__Instance)->data);
            }

            set
            {
                ((__Internal*)__Instance)->data = value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray Dims
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->dims, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->dims = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteType Type
        {
            get
            {
                return ((__Internal*)__Instance)->type;
            }

            set
            {
                ((__Internal*)__Instance)->type = value;
            }
        }
    }

    public unsafe partial class TfLiteDelegateParams : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 32)]
        public partial struct __Internal
        {
            internal __IntPtr @delegate;
            internal __IntPtr nodes_to_replace;
            internal __IntPtr input_tensors;
            internal __IntPtr output_tensors;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteDelegateParams@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteDelegateParams> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteDelegateParams>();

        protected bool __ownsNativeInstance;

        internal static TfLiteDelegateParams __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteDelegateParams(native.ToPointer(), skipVTables);
        }

        internal static TfLiteDelegateParams __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteDelegateParams)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteDelegateParams __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteDelegateParams(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteDelegateParams(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteDelegateParams(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteDelegateParams()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteDelegateParams.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteDelegateParams(global::tensorflowlite_c.TfLiteDelegateParams _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteDelegateParams.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteDelegateParams.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteDelegateParams.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.TfLiteDelegate Delegate
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteDelegate.__GetOrCreateInstance(((__Internal*)__Instance)->@delegate, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->@delegate = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray NodesToReplace
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->nodes_to_replace, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->nodes_to_replace = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray InputTensors
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->input_tensors, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->input_tensors = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public global::tensorflowlite_c.TfLiteIntArray OutputTensors
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(((__Internal*)__Instance)->output_tensors, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->output_tensors = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }
    }

    public unsafe partial class TfLiteContext : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 176)]
        public partial struct __Internal
        {
            internal ulong tensors_size;
            internal __IntPtr GetExecutionPlan;
            internal __IntPtr tensors;
            internal __IntPtr impl_;
            internal __IntPtr ResizeTensor;
            internal __IntPtr ReportError;
            internal __IntPtr AddTensors;
            internal __IntPtr GetNodeAndRegistration;
            internal __IntPtr ReplaceNodeSubsetsWithDelegateKernels;
            internal int recommended_num_threads;
            internal __IntPtr GetExternalContext;
            internal __IntPtr SetExternalContext;
            internal byte allow_fp32_relax_to_fp16;
            internal __IntPtr profiler;
            internal __IntPtr AllocatePersistentBuffer;
            internal __IntPtr AllocateBufferForEval;
            internal __IntPtr RequestScratchBufferInArena;
            internal __IntPtr GetScratchBuffer;
            internal __IntPtr ResizeTensorExplicit;
            internal __IntPtr PreviewDelegatePartitioning;
            internal __IntPtr GetTensor;
            internal __IntPtr GetEvalTensor;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteContext@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteContext> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteContext>();

        protected bool __ownsNativeInstance;

        internal static TfLiteContext __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteContext(native.ToPointer(), skipVTables);
        }

        internal static TfLiteContext __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteContext)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteContext __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteContext(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteContext(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteContext(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteContext()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteContext.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteContext(global::tensorflowlite_c.TfLiteContext _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteContext.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteContext.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteContext.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public ulong TensorsSize
        {
            get
            {
                return ((__Internal*)__Instance)->tensors_size;
            }

            set
            {
                ((__Internal*)__Instance)->tensors_size = value;
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr GetExecutionPlan
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->GetExecutionPlan;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->GetExecutionPlan = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.TfLiteTensor Tensors
        {
            get
            {
                var __result0 = global::tensorflowlite_c.TfLiteTensor.__GetOrCreateInstance(((__Internal*)__Instance)->tensors, false);
                return __result0;
            }

            set
            {
                ((__Internal*)__Instance)->tensors = value is null ? __IntPtr.Zero : value.__Instance;
            }
        }

        public __IntPtr Impl
        {
            get
            {
                return ((__Internal*)__Instance)->impl_;
            }

            set
            {
                ((__Internal*)__Instance)->impl_ = (__IntPtr) value;
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr ResizeTensor
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->ResizeTensor;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->ResizeTensor = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Action___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string ReportError
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->ReportError;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Action___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Action___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string));
            }

            set
            {
                ((__Internal*)__Instance)->ReportError = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_int_intPtr AddTensors
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->AddTensors;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_int_intPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_int_intPtr));
            }

            set
            {
                ((__Internal*)__Instance)->AddTensors = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_int___IntPtr___IntPtr GetNodeAndRegistration
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->GetNodeAndRegistration;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_int___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_int___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->GetNodeAndRegistration = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_tensorflowlite_c_TfLiteRegistration___Internal___IntPtr___IntPtr ReplaceNodeSubsetsWithDelegateKernels
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->ReplaceNodeSubsetsWithDelegateKernels;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_tensorflowlite_c_TfLiteRegistration___Internal___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_tensorflowlite_c_TfLiteRegistration___Internal___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->ReplaceNodeSubsetsWithDelegateKernels = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public int RecommendedNumThreads
        {
            get
            {
                return ((__Internal*)__Instance)->recommended_num_threads;
            }

            set
            {
                ((__Internal*)__Instance)->recommended_num_threads = value;
            }
        }

        public global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_tensorflowlite_c_TfLiteExternalContextType GetExternalContext
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->GetExternalContext;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_tensorflowlite_c_TfLiteExternalContextType) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_tensorflowlite_c_TfLiteExternalContextType));
            }

            set
            {
                ((__Internal*)__Instance)->GetExternalContext = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Action___IntPtr_tensorflowlite_c_TfLiteExternalContextType___IntPtr SetExternalContext
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->SetExternalContext;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Action___IntPtr_tensorflowlite_c_TfLiteExternalContextType___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Action___IntPtr_tensorflowlite_c_TfLiteExternalContextType___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->SetExternalContext = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public bool AllowFp32RelaxToFp16
        {
            get
            {
                return ((__Internal*)__Instance)->allow_fp32_relax_to_fp16 != 0;
            }

            set
            {
                ((__Internal*)__Instance)->allow_fp32_relax_to_fp16 = (byte) (value ? 1 : 0);
            }
        }

        public __IntPtr Profiler
        {
            get
            {
                return ((__Internal*)__Instance)->profiler;
            }

            set
            {
                ((__Internal*)__Instance)->profiler = (__IntPtr) value;
            }
        }

        public global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_ulong AllocatePersistentBuffer
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->AllocatePersistentBuffer;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_ulong) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_ulong));
            }

            set
            {
                ((__Internal*)__Instance)->AllocatePersistentBuffer = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_voidPtrPtr AllocateBufferForEval
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->AllocateBufferForEval;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_voidPtrPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_voidPtrPtr));
            }

            set
            {
                ((__Internal*)__Instance)->AllocateBufferForEval = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_intPtr RequestScratchBufferInArena
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->RequestScratchBufferInArena;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_intPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_intPtr));
            }

            set
            {
                ((__Internal*)__Instance)->RequestScratchBufferInArena = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int GetScratchBuffer
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->GetScratchBuffer;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int));
            }

            set
            {
                ((__Internal*)__Instance)->GetScratchBuffer = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int_intPtr ResizeTensorExplicit
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->ResizeTensorExplicit;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int_intPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int_intPtr));
            }

            set
            {
                ((__Internal*)__Instance)->ResizeTensorExplicit = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr_intPtr PreviewDelegatePartitioning
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->PreviewDelegatePartitioning;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr_intPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr_intPtr));
            }

            set
            {
                ((__Internal*)__Instance)->PreviewDelegatePartitioning = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int GetTensor
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->GetTensor;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int));
            }

            set
            {
                ((__Internal*)__Instance)->GetTensor = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int GetEvalTensor
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->GetEvalTensor;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr_int));
            }

            set
            {
                ((__Internal*)__Instance)->GetEvalTensor = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }
    }

    public unsafe partial class TfLiteRegistration : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 64)]
        public partial struct __Internal
        {
            internal __IntPtr init;
            internal __IntPtr free;
            internal __IntPtr prepare;
            internal __IntPtr invoke;
            internal __IntPtr profiling_string;
            internal int builtin_code;
            internal __IntPtr custom_name;
            internal int version;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteRegistration@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteRegistration> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteRegistration>();
        private bool __custom_name_OwnsNativeMemory = false;

        protected bool __ownsNativeInstance;

        internal static TfLiteRegistration __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteRegistration(native.ToPointer(), skipVTables);
        }

        internal static TfLiteRegistration __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteRegistration)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteRegistration __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteRegistration(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteRegistration(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteRegistration(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteRegistration()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteRegistration.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteRegistration(global::tensorflowlite_c.TfLiteRegistration _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteRegistration.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteRegistration.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteRegistration.__Internal*) _0.__Instance);
            if (_0.__custom_name_OwnsNativeMemory)
                this.CustomName = _0.CustomName;
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__custom_name_OwnsNativeMemory)
                Marshal.FreeHGlobal(((__Internal*)__Instance)->custom_name);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string_ulong Init
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->init;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string_ulong) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string_ulong));
            }

            set
            {
                ((__Internal*)__Instance)->init = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Action___IntPtr___IntPtr Free
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->free;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Action___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Action___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->free = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr Prepare
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->prepare;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->prepare = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr Invoke
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->invoke;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->invoke = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr___IntPtr ProfilingString
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->profiling_string;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func___IntPtr___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->profiling_string = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public int BuiltinCode
        {
            get
            {
                return ((__Internal*)__Instance)->builtin_code;
            }

            set
            {
                ((__Internal*)__Instance)->builtin_code = value;
            }
        }

        public string CustomName
        {
            get
            {
                return CppSharp.Runtime.MarshalUtil.GetString(global::System.Text.Encoding.UTF8, ((__Internal*)__Instance)->custom_name);
            }

            set
            {
                if (__custom_name_OwnsNativeMemory)
                    Marshal.FreeHGlobal(((__Internal*)__Instance)->custom_name);
                __custom_name_OwnsNativeMemory = true;
                if (value == null)
                {
                    ((__Internal*)__Instance)->custom_name = global::System.IntPtr.Zero;
                    return;
                }
                var __bytes0 = global::System.Text.Encoding.UTF8.GetBytes(value);
                var __bytePtr0 = Marshal.AllocHGlobal(__bytes0.Length + 1);
                Marshal.Copy(__bytes0, 0, __bytePtr0, __bytes0.Length);
                Marshal.WriteByte(__bytePtr0 + __bytes0.Length, 0);
                ((__Internal*)__Instance)->custom_name = (__IntPtr) __bytePtr0;
            }
        }

        public int Version
        {
            get
            {
                return ((__Internal*)__Instance)->version;
            }

            set
            {
                ((__Internal*)__Instance)->version = value;
            }
        }
    }

    public unsafe partial class TfLiteDelegate : IDisposable
    {
        [StructLayout(LayoutKind.Sequential, Size = 48)]
        public partial struct __Internal
        {
            internal __IntPtr data_;
            internal __IntPtr Prepare;
            internal __IntPtr CopyFromBufferHandle;
            internal __IntPtr CopyToBufferHandle;
            internal __IntPtr FreeBufferHandle;
            internal long flags;

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "??0TfLiteDelegate@@QEAA@AEBU0@@Z", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr cctor(__IntPtr __instance, __IntPtr _0);
        }

        public __IntPtr __Instance { get; protected set; }

        internal static readonly global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteDelegate> NativeToManagedMap = new global::System.Collections.Concurrent.ConcurrentDictionary<IntPtr, global::tensorflowlite_c.TfLiteDelegate>();

        protected bool __ownsNativeInstance;

        internal static TfLiteDelegate __CreateInstance(__IntPtr native, bool skipVTables = false)
        {
            return new TfLiteDelegate(native.ToPointer(), skipVTables);
        }

        internal static TfLiteDelegate __GetOrCreateInstance(__IntPtr native, bool saveInstance = false, bool skipVTables = false)
        {
            if (native == __IntPtr.Zero)
                return null;
            if (NativeToManagedMap.TryGetValue(native, out var managed))
                return (TfLiteDelegate)managed;
            var result = __CreateInstance(native, skipVTables);
            if (saveInstance)
                NativeToManagedMap[native] = result;
            return result;
        }

        internal static TfLiteDelegate __CreateInstance(__Internal native, bool skipVTables = false)
        {
            return new TfLiteDelegate(native, skipVTables);
        }

        private static void* __CopyValue(__Internal native)
        {
            var ret = Marshal.AllocHGlobal(sizeof(__Internal));
            *(__Internal*) ret = native;
            return ret.ToPointer();
        }

        private TfLiteDelegate(__Internal native, bool skipVTables = false)
            : this(__CopyValue(native), skipVTables)
        {
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        protected TfLiteDelegate(void* native, bool skipVTables = false)
        {
            if (native == null)
                return;
            __Instance = new __IntPtr(native);
        }

        public TfLiteDelegate()
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteDelegate.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
        }

        public TfLiteDelegate(global::tensorflowlite_c.TfLiteDelegate _0)
        {
            __Instance = Marshal.AllocHGlobal(sizeof(global::tensorflowlite_c.TfLiteDelegate.__Internal));
            __ownsNativeInstance = true;
            NativeToManagedMap[__Instance] = this;
            *((global::tensorflowlite_c.TfLiteDelegate.__Internal*) __Instance) = *((global::tensorflowlite_c.TfLiteDelegate.__Internal*) _0.__Instance);
        }

        public void Dispose()
        {
            Dispose(disposing: true, callNativeDtor : __ownsNativeInstance );
        }

        partial void DisposePartial(bool disposing);

        internal protected virtual void Dispose(bool disposing, bool callNativeDtor )
        {
            if (__Instance == IntPtr.Zero)
                return;
            NativeToManagedMap.TryRemove(__Instance, out _);
            DisposePartial(disposing);
            if (__ownsNativeInstance)
                Marshal.FreeHGlobal(__Instance);
            __Instance = IntPtr.Zero;
        }

        public __IntPtr Data
        {
            get
            {
                return ((__Internal*)__Instance)->data_;
            }

            set
            {
                ((__Internal*)__Instance)->data_ = (__IntPtr) value;
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr Prepare
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->Prepare;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->Prepare = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int___IntPtr CopyFromBufferHandle
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->CopyFromBufferHandle;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->CopyFromBufferHandle = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int___IntPtr CopyToBufferHandle
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->CopyToBufferHandle;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int___IntPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int___IntPtr));
            }

            set
            {
                ((__Internal*)__Instance)->CopyToBufferHandle = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public global::tensorflowlite_c.Delegates.Action___IntPtr___IntPtr_intPtr FreeBufferHandle
        {
            get
            {
                var __ptr0 = ((__Internal*)__Instance)->FreeBufferHandle;
                return __ptr0 == IntPtr.Zero? null : (global::tensorflowlite_c.Delegates.Action___IntPtr___IntPtr_intPtr) Marshal.GetDelegateForFunctionPointer(__ptr0, typeof(global::tensorflowlite_c.Delegates.Action___IntPtr___IntPtr_intPtr));
            }

            set
            {
                ((__Internal*)__Instance)->FreeBufferHandle = value == null ? global::System.IntPtr.Zero : Marshal.GetFunctionPointerForDelegate(value);
            }
        }

        public long Flags
        {
            get
            {
                return ((__Internal*)__Instance)->flags;
            }

            set
            {
                ((__Internal*)__Instance)->flags = value;
            }
        }
    }

    public unsafe partial class common
    {
        public partial struct __Internal
        {
            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteIntArrayGetSizeInBytes", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteIntArrayGetSizeInBytes(int size);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteIntArrayCreate", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteIntArrayCreate(int size);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteIntArrayEqual", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteIntArrayEqual(__IntPtr a, __IntPtr b);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteIntArrayEqualsArray", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteIntArrayEqualsArray(__IntPtr a, int b_size, int[] b_data);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteIntArrayCopy", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteIntArrayCopy(__IntPtr src);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteIntArrayFree", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteIntArrayFree(__IntPtr a);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteFloatArrayGetSizeInBytes", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern int TfLiteFloatArrayGetSizeInBytes(int size);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteFloatArrayCreate", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteFloatArrayCreate(int size);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteFloatArrayFree", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteFloatArrayFree(__IntPtr a);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTypeGetName", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern __IntPtr TfLiteTypeGetName(global::tensorflowlite_c.TfLiteType type);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorDataFree", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteTensorDataFree(__IntPtr t);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteQuantizationFree", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteQuantizationFree(__IntPtr quantization);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteSparsityFree", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteSparsityFree(__IntPtr sparsity);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorFree", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteTensorFree(__IntPtr t);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorReset", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteTensorReset(global::tensorflowlite_c.TfLiteType type, [MarshalAs(UnmanagedType.CustomMarshaler, MarshalTypeRef = typeof(CppSharp.Runtime.UTF8Marshaller))] string name, __IntPtr dims, global::tensorflowlite_c.TfLiteQuantizationParams.__Internal quantization, sbyte* buffer, ulong size, global::tensorflowlite_c.TfLiteAllocationType allocation_type, __IntPtr allocation, bool is_variable, __IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteTensorRealloc", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteTensorRealloc(ulong num_bytes, __IntPtr tensor);

            [SuppressUnmanagedCodeSecurity, DllImport(LibNames.TFLiteLib, EntryPoint = "TfLiteDelegateCreate", CallingConvention = __CallingConvention.Cdecl)]
            internal static extern void TfLiteDelegateCreate(__IntPtr @return);
        }

        public static int TfLiteIntArrayGetSizeInBytes(int size)
        {
            var __ret = __Internal.TfLiteIntArrayGetSizeInBytes(size);
            return __ret;
        }

        public static global::tensorflowlite_c.TfLiteIntArray TfLiteIntArrayCreate(int size)
        {
            var __ret = __Internal.TfLiteIntArrayCreate(size);
            var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static int TfLiteIntArrayEqual(global::tensorflowlite_c.TfLiteIntArray a, global::tensorflowlite_c.TfLiteIntArray b)
        {
            var __arg0 = a is null ? __IntPtr.Zero : a.__Instance;
            var __arg1 = b is null ? __IntPtr.Zero : b.__Instance;
            var __ret = __Internal.TfLiteIntArrayEqual(__arg0, __arg1);
            return __ret;
        }

        public static int TfLiteIntArrayEqualsArray(global::tensorflowlite_c.TfLiteIntArray a, int b_size, int[] b_data)
        {
            var __arg0 = a is null ? __IntPtr.Zero : a.__Instance;
            var __ret = __Internal.TfLiteIntArrayEqualsArray(__arg0, b_size, b_data);
            return __ret;
        }

        public static global::tensorflowlite_c.TfLiteIntArray TfLiteIntArrayCopy(global::tensorflowlite_c.TfLiteIntArray src)
        {
            var __arg0 = src is null ? __IntPtr.Zero : src.__Instance;
            var __ret = __Internal.TfLiteIntArrayCopy(__arg0);
            var __result0 = global::tensorflowlite_c.TfLiteIntArray.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static void TfLiteIntArrayFree(global::tensorflowlite_c.TfLiteIntArray a)
        {
            var __arg0 = a is null ? __IntPtr.Zero : a.__Instance;
            __Internal.TfLiteIntArrayFree(__arg0);
        }

        public static int TfLiteFloatArrayGetSizeInBytes(int size)
        {
            var __ret = __Internal.TfLiteFloatArrayGetSizeInBytes(size);
            return __ret;
        }

        public static global::tensorflowlite_c.TfLiteFloatArray TfLiteFloatArrayCreate(int size)
        {
            var __ret = __Internal.TfLiteFloatArrayCreate(size);
            var __result0 = global::tensorflowlite_c.TfLiteFloatArray.__GetOrCreateInstance(__ret, false);
            return __result0;
        }

        public static void TfLiteFloatArrayFree(global::tensorflowlite_c.TfLiteFloatArray a)
        {
            var __arg0 = a is null ? __IntPtr.Zero : a.__Instance;
            __Internal.TfLiteFloatArrayFree(__arg0);
        }

        public static string TfLiteTypeGetName(global::tensorflowlite_c.TfLiteType type)
        {
            var __ret = __Internal.TfLiteTypeGetName(type);
            return CppSharp.Runtime.MarshalUtil.GetString(global::System.Text.Encoding.UTF8, __ret);
        }

        public static void TfLiteTensorDataFree(global::tensorflowlite_c.TfLiteTensor t)
        {
            var __arg0 = t is null ? __IntPtr.Zero : t.__Instance;
            __Internal.TfLiteTensorDataFree(__arg0);
        }

        public static void TfLiteQuantizationFree(global::tensorflowlite_c.TfLiteQuantization quantization)
        {
            var __arg0 = quantization is null ? __IntPtr.Zero : quantization.__Instance;
            __Internal.TfLiteQuantizationFree(__arg0);
        }

        public static void TfLiteSparsityFree(global::tensorflowlite_c.TfLiteSparsity sparsity)
        {
            var __arg0 = sparsity is null ? __IntPtr.Zero : sparsity.__Instance;
            __Internal.TfLiteSparsityFree(__arg0);
        }

        public static void TfLiteTensorFree(global::tensorflowlite_c.TfLiteTensor t)
        {
            var __arg0 = t is null ? __IntPtr.Zero : t.__Instance;
            __Internal.TfLiteTensorFree(__arg0);
        }

        public static void TfLiteTensorReset(global::tensorflowlite_c.TfLiteType type, string name, global::tensorflowlite_c.TfLiteIntArray dims, global::tensorflowlite_c.TfLiteQuantizationParams quantization, sbyte* buffer, ulong size, global::tensorflowlite_c.TfLiteAllocationType allocation_type, __IntPtr allocation, bool is_variable, global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg2 = dims is null ? __IntPtr.Zero : dims.__Instance;
            if (ReferenceEquals(quantization, null))
                throw new global::System.ArgumentNullException("quantization", "Cannot be null because it is passed by value.");
            var __arg3 = quantization.__Instance;
            var __arg9 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            __Internal.TfLiteTensorReset(type, name, __arg2, *(global::tensorflowlite_c.TfLiteQuantizationParams.__Internal*) __arg3, buffer, size, allocation_type, allocation, is_variable, __arg9);
        }

        public static void TfLiteTensorRealloc(ulong num_bytes, global::tensorflowlite_c.TfLiteTensor tensor)
        {
            var __arg1 = tensor is null ? __IntPtr.Zero : tensor.__Instance;
            __Internal.TfLiteTensorRealloc(num_bytes, __arg1);
        }

        public static global::tensorflowlite_c.TfLiteDelegate TfLiteDelegateCreate()
        {
            var __ret = new global::tensorflowlite_c.TfLiteDelegate.__Internal();
            __Internal.TfLiteDelegateCreate(new IntPtr(&__ret));
            return global::tensorflowlite_c.TfLiteDelegate.__CreateInstance(__ret);
        }
    }

    namespace Delegates
    {
        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr(__IntPtr context);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr(__IntPtr context, __IntPtr @delegate);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int___IntPtr(__IntPtr context, __IntPtr @delegate, int buffer_handle, __IntPtr tensor);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate void Action___IntPtr___IntPtr_intPtr(__IntPtr context, __IntPtr @delegate, int* handle);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr(__IntPtr __0, __IntPtr tensor, __IntPtr new_size);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate void Action___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string(__IntPtr __0, [MarshalAs(UnmanagedType.CustomMarshaler, MarshalTypeRef = typeof(CppSharp.Runtime.UTF8Marshaller))] string msg);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr_int_intPtr(__IntPtr __0, int tensors_to_add, int* first_new_tensor_index);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr_int___IntPtr___IntPtr(__IntPtr __0, int node_index, __IntPtr node, __IntPtr registration);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr_tensorflowlite_c_TfLiteRegistration___Internal___IntPtr___IntPtr(__IntPtr __0, global::tensorflowlite_c.TfLiteRegistration.__Internal registration, __IntPtr nodes_to_replace, __IntPtr @delegate);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate __IntPtr Func___IntPtr___IntPtr_tensorflowlite_c_TfLiteExternalContextType(__IntPtr __0, global::tensorflowlite_c.TfLiteExternalContextType __1);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate void Action___IntPtr_tensorflowlite_c_TfLiteExternalContextType___IntPtr(__IntPtr __0, global::tensorflowlite_c.TfLiteExternalContextType __1, __IntPtr __2);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate __IntPtr Func___IntPtr___IntPtr_ulong(__IntPtr ctx, ulong bytes);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_voidPtrPtr(__IntPtr ctx, ulong bytes, void** ptr);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr_ulong_intPtr(__IntPtr ctx, ulong bytes, int* buffer_idx);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate __IntPtr Func___IntPtr___IntPtr_int(__IntPtr ctx, int buffer_idx);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr_int_intPtr(__IntPtr ctx, __IntPtr tensor, int dims, int* shape);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate global::tensorflowlite_c.TfLiteStatus Func_tensorflowlite_c_TfLiteStatus___IntPtr___IntPtr___IntPtr_intPtr(__IntPtr context, __IntPtr nodes_to_replace, __IntPtr partition_params_array, int* num_partitions);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate __IntPtr Func___IntPtr___IntPtr__MarshalAs_UnmanagedType_CustomMarshaler__MarshalTypeRef___typeof_CppSharp_Runtime_UTF8Marshaller____string_ulong(__IntPtr context, [MarshalAs(UnmanagedType.CustomMarshaler, MarshalTypeRef = typeof(CppSharp.Runtime.UTF8Marshaller))] string buffer, ulong length);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate void Action___IntPtr___IntPtr(__IntPtr context, __IntPtr buffer);

        [SuppressUnmanagedCodeSecurity, UnmanagedFunctionPointer(__CallingConvention.Cdecl)]
        public unsafe delegate __IntPtr Func___IntPtr___IntPtr___IntPtr(__IntPtr context, __IntPtr node);
    }
}
